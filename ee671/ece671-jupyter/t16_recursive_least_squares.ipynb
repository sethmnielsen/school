{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 16.  Recursive Least Squares\n",
    "Author: Seth Nielsen - sethmnielsen@gmail.com\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "\n",
    "Least squares approximation is a method used to approximate the solution to a system of equations. Linear least squares can be applied to a set of data to find a model that minimizes the sum of the squared errors between the data and their corresponding modeled values, thus creating a model of best fit. This method can further be applied to create a least-squares filter; a type of filter that, given a sequence of input data, uses least squares to find the coefficients that minimize the error between the filter's output and a desired sequence. \n",
    "\n",
    "The traditional form of a least squares filter is performed in *batch* form, where the minimizing solution is computed on an entire block of data after the data has been collected. This method of calculating a solution can be effective for applications suited to offline computation, but is not particularly useful for systems that require real-time or online parameter estimation for parameters that are unknown in advance or are changing. In this case, an adaptive filter is required. The recursive least squares filter modifies the least squares filter to be adaptive by continuously updating the estimated parameters (coefficients) as new data arrive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the theory\n",
    "\n",
    "Give a detailed discussion (i.e., equations galore) of the topic.Â  \n",
    "The emphasis here is clarity for future students learning the topic.\n",
    "\n",
    "Least squares filter:\n",
    "\n",
    "\\begin{equation}\n",
    "Rh = A^H d, \\text{ where } R = A^H A = \\sum_{i=1}^N q_{i}\\ q_{i}^H \\\\\n",
    "\\text{with } q_i = \\begin{bmatrix}f_{i}\\\\f_{i-1}\\\\...\\\\f_{i-m+1}\\end{bmatrix} \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Let}\\ \\ p &= A^H d = \\sum_{i=1}^N q_{i}d_i \\\\\n",
    "h &= R^{-1}A^{H} = R^{-1}p \\\\\n",
    "\\end{align}\n",
    "\n",
    "Start RLS algorithm:\n",
    "\n",
    "\\begin{equation}\n",
    "R_t = \\sum_{i=1}^t q_{i}q_{i}^H \\\\\n",
    "p_t = \\sum_{i=1}^t q_{i}d_i = p_{t-1} + q_{t}d_{t} \\\\\n",
    "h_t = R_{t}^{-1}p_t \\\\\n",
    "\\end{equation}\n",
    "\n",
    "Algorithm is now adaptive, but needs to be recursive ($R_{t}^{-1}$ is currently calculated at each time step). We can break $R_t$ up as\n",
    "\n",
    "\\begin{align}\n",
    "R_t &= \\sum_{i=1}^{t-1}{q_i}{q_{i}^H} + {q_t}{q_{t}^H} \\\\\n",
    "    &= R_{t-1} + q_{t}q_{t}^H\n",
    "\\end{align}\n",
    "\n",
    "By the Sherman-Morrison formula (eq. 4.32),\n",
    "\n",
    "\\begin{equation}\n",
    "R_{t}^{-1} = R_{t-1}^{-1} - \\frac{R_{t-1}^{-1}{q_t}\\:{q_{t}^H}\\:R_{t-1}^{-1}}{1 + {q_{t}^H}\\:{R_{t-1}^{-1}}{q_t}}\n",
    "\\end{equation}\n",
    "\n",
    "Let\n",
    "\n",
    "\\begin{align}\n",
    "P_t &= R_{t}^{-1} \\\\\n",
    "k_t &= \\frac{R_{t-1}^{-1}{q_t}}{1 + {q_{t}^H}{R_{t-1}^{-1}}{q_t}}.\n",
    "\\end{align}\n",
    "\n",
    "Then we arrive at\n",
    "\\begin{equation}\n",
    "P_t = P_{t-1} - {k_t}\\:{q_{t}^H}{P_{t-1}}. \\quad \\text{(eq. 4.38)}\n",
    "\\end{equation}\n",
    "\n",
    "The coefficients for the filter, or the estimated parameters, are computed by\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{h}_t &= P_t p_t = P_t (\\ p_{t-1} + q_t\\ d_t\\ ) \\\\\n",
    "&= P_t\\ p_{t-1} + P_t\\ q_t\\ d_t \\\\\n",
    "&= P_{t-1}\\ p_{t-1} - k_t\\ q_t^H\\ P_{t-1}\\ p_{t-1} + P_t\\ q_t\\ d_t \\ \\Leftarrow\\ \\text{using (eq. 4.38)} \\\\\n",
    "&= \\hat{h}_{t-1} - k_t\\ q_t^H\\ \\hat{h}_{t-1} + k_t\\ d_t \\qquad \\qquad \\quad \\Leftarrow\\ k_t = P_t\\ q_t \\\\\n",
    "&= \\hat{h}_{t-1} + k_t (\\ d_t - q_t^H\\ \\hat{h}_{t-1}\\ ).\n",
    "\\end{align}\n",
    "\n",
    "The quantity multiplied by $k_t$ respresents the filter error\n",
    "\n",
    "\\begin{equation}\n",
    "\\varepsilon_t = d_t - q_t^H\\ \\hat{h}_{t-1},\n",
    "\\end{equation}\n",
    "\n",
    "which allows us to write the update of the filter coefficients in the simple form of\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{h}_t = \\hat{h}_{t-1} + k_t \\varepsilon_t.\n",
    "\\end{equation}\n",
    "\n",
    "### Initialization\n",
    "\n",
    "To initialize the algorithm, the initial condition $P_0 = R_{0}^{-1}$ is needed. A slight perturbation of some small $\\delta$ to the matrix $R_t$ gives the following:\n",
    "\\begin{align}\n",
    "R_t &= \\sum_{i=1}^t q_{i}q_{i}^H + \\delta I \\\\\n",
    "R_0 &= \\delta I \\\\\n",
    "P_0 &= \\delta^{-1} I\n",
    "\\end{align}\n",
    "\n",
    "The initial filter coefficients can be assumed to be zero, and thus $\\hat{h}_0 = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Numerical Examples\n",
    "\n",
    "Provide some simple python code and examples that emphasize the basic concepts.\n",
    "\n",
    "We can start by estimating the parameters of a simple system with impulse response $h = [\\ 1,2,3,4,5\\ ]$ using a recursive least squares filter. The following filter written in Python will give normally-distributed random values $f_t$ as inputs and attempt to match the system's true output $d_t$ by computing the error $\\varepsilon_t = d_t - y_t$ , where $y_t$ is the filtered output evaluated as $y_t = q_{t}^H \\ \\hat{h}_t$, and $\\hat{h}_t$ is the vector of estimated parameters that is updated by computing $\\hat{h}_t = \\hat{h}_{t-1} + k_t \\varepsilon_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhat: [1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "\n",
    "m = 5      # number of parameters\n",
    "n = 1000   # iterations\n",
    "\n",
    "h = np.array([1,2,3,4,5])  # impulse response\n",
    "hhat = np.zeros(m)         # initial estimated parameters\n",
    "f = np.random.randn(n)     # normally-distributed random input\n",
    "fn = np.hstack(([0,0,0,0],f))  # convenience array used to shift through input (f)\n",
    "q = np.zeros(m)  # input data for one time step\n",
    "delta = .0001\n",
    "P = 1/delta * np.eye(m)  # initialize P[0] without calculating inverse of R[0]\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    d = fn[i:i+5] @ h  # true output\n",
    "    q = fn[i:i+m]      # q update\n",
    "\n",
    "    k = P @ q / (1 + q.T @ P @ q)  # kalman gain vector\n",
    "    y = q @ hhat  # filter output\n",
    "    e = d - y     # error\n",
    "    \n",
    "    hhat = hhat + k * e  # update of estimated parameters\n",
    "    P = P - k * q @ P    # P update\n",
    "\n",
    "print('hhat:',hhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Engineering Application\n",
    "\n",
    "Provide a more sophisticated example showing one engineering example of the topic, complete with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass-Spring-Damper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
